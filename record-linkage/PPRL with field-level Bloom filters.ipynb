{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from hashlib import sha256\n",
    "from nltk import ngrams\n",
    "from struct import pack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPRL with field-level Bloom filters\n",
    "For a Bloom filter we define:\n",
    "\n",
    "- a bit vector $v$ of length $l$ with all values initially set to $0$;\n",
    "- a set $H$ with $k$ independent hash functions with range $0$ to $l - 1$.\n",
    "\n",
    "To convert a set $S$ to a Bloom filter:\n",
    "\n",
    "- each element $x_i \\in S$ is hashed using the $k$ hash functions;\n",
    "- all bits in $v$ with indices $h_j(x_i)$, for $1 \\leq j \\leq k$, are set to $1$;\n",
    "\n",
    "First, all fields are converted to a set of n-grams. This n-gram set is used to create field-level Bloom filters (FBFs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 512\n",
    "k = 2\n",
    "H = [sha256(sha256(bytes(i)).digest()) for i in range(k)]\n",
    "\n",
    "def n_grams(field):\n",
    "    \"\"\"Converts a field to a set of n-grams.\"\"\"\n",
    "    return [''.join(ng) for ng in ngrams(' {} '.format(field), 2)]\n",
    "\n",
    "def bit_vector(size):\n",
    "    \"\"\"Returns a bit vector with all values set to zero.\"\"\"\n",
    "    return [0 for _ in range(size)]\n",
    "\n",
    "def hash_indices(x):\n",
    "    \"\"\"Returns the indices generated by h(x).\"\"\"\n",
    "    if type(x) is str:\n",
    "        x = x.encode('UTF-8')\n",
    "    \n",
    "    for h in H:\n",
    "        g = h.copy()\n",
    "        g.update(x)\n",
    "        \n",
    "        digest = int(g.hexdigest(), 16)\n",
    "        yield digest % l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = ('John', 'Smith', 'Amsterdam')\n",
    "p2 = ('John', 'Smyth', 'Amsterdam')\n",
    "p3 = ('Johhny', 'Smith', 'Den Haag')\n",
    "\n",
    "p1_S = [n_grams(f) for f in p1]\n",
    "p2_S = [n_grams(f) for f in p2]\n",
    "p3_S = [n_grams(f) for f in p3]\n",
    "\n",
    "p1_v = [bit_vector(l) for _ in p1]\n",
    "p2_v = [bit_vector(l) for _ in p2]\n",
    "p3_v = [bit_vector(l) for _ in p3]\n",
    "\n",
    "all_p = [p1] + [p2] + [p3]\n",
    "all_S = p1_S + p2_S + p3_S\n",
    "all_v = p1_v + p2_v + p3_v\n",
    "\n",
    "# Construct FBFs.\n",
    "for (S, v) in zip(all_S, all_v):\n",
    "    for x in S:\n",
    "        for i in hash_indices(x):\n",
    "            v[i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity between FBFs is calculated using the Dice-coefficient:\n",
    "\n",
    "$$Dice\\_sim(v_1, v_2) = \\frac{2c}{x_1 + x_2}$$\n",
    "\n",
    "- $c$ is the number of common bit positions in $v_1$ and $v_2$ that are set to $1$;\n",
    "- $x_1$ is the number of bit positions in $v_1$ set to $1$;\n",
    "- $x_2$ is the number of bit positions in $v_2$ set to $1$.\n",
    "\n",
    "The similarity of two records is the mean of all pairwise FBF similarities:\n",
    "\n",
    "$$record\\_sim(V_a, V_b) = \\frac{1}{n}\\sum_{i=1}^{n}{Dice\\_sim(v_{i}^{(a)}, v_{i}^{(b)})}$$\n",
    "\n",
    "- $V_a$ is the ordered list of $n$ FBFs constructed from record $a$;\n",
    "- $V_b$ is the ordered list of $n$ FBFs constructed from record $b$;\n",
    "- $v_{i}^{(a)}$ is the $i$-th FBF from $V_a$;\n",
    "- $v_{i}^{(b)}$ is the $i$-th FBF from $V_b$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'John Smith Amsterdam' and 'John Smyth Amsterdam': 0.889\n",
      "Similarity between 'John Smith Amsterdam' and 'Johhny Smith Den Haag': 0.574\n",
      "Similarity between 'John Smyth Amsterdam' and 'Johhny Smith Den Haag': 0.462\n"
     ]
    }
   ],
   "source": [
    "def dice_sim(a, b):\n",
    "    c = sum([1 for (i, j) in zip(a, b) if i + j == 2])\n",
    "    x1 = sum(a)\n",
    "    x2 = sum(b)\n",
    "        \n",
    "    return (2*c) / (x1 + x2)\n",
    "\n",
    "def record_sim(Va, Vb):\n",
    "    s = 0\n",
    "    for (va, vb) in zip(Va, Vb):\n",
    "        s += dice_sim(va, vb)\n",
    "\n",
    "    return s / len(Va)\n",
    "    \n",
    "for (a, b) in combinations([(p1, p1_v), (p2, p2_v), (p3, p3_v)], 2):\n",
    "    record_a = ' '.join(a[0])\n",
    "    record_b = ' '.join(b[0])\n",
    "    similarity = record_sim(a[1], b[1])\n",
    "    \n",
    "    print('Similarity between \\'{0}\\' and \\'{1}\\': {2:.3}'.format(record_a, record_b, similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Privacy-preserving record linkage using Bloom filters](https://www.semanticscholar.org/paper/Privacy-preserving-record-linkage-using-Bloom-filt-Schnell-Bachteler/8392fa13e5013073b617e947b0229bf1734990ac)\n",
    "- [Composite Bloom filters for secure record linkage](https://www.semanticscholar.org/paper/Composite-Bloom-Filters-for-Secure-Record-Linkage-Durham-Kantarcioglu/bb1dbac86d922b91daabf61ec75f56dde47997be)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
