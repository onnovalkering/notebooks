{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadoop â€“ Streaming\n",
    "https://www.tutorialspoint.com/hadoop/hadoop_streaming.htm\n",
    "\n",
    "The code in the above tutorial doesn't work (incorrect, Python 2.7) on the Bitnami Hadoop VM version 3.3.0 (October 2020).\n",
    "\n",
    "Use the following code as `mapper.py` and `reducer.py`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    words = line.strip().split(' ')\n",
    "    \n",
    "    for word in words:\n",
    "        print(f'{word}\\t1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys \n",
    "\n",
    "counts = {}\n",
    "\n",
    "for line in sys.stdin:\n",
    "    word, count = line.strip().split('\\t')\n",
    "\n",
    "    try:\n",
    "        count = int(count)\n",
    "        counts[word] = counts.get(word, 0) + count\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for (word, count) in counts.items():\n",
    "    print(f'{word}\\t{count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this word count example, first download the correct Hadoop streaming library:\n",
    "```shell\n",
    "curl -LO \"https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-streaming/3.3.0/hadoop-streaming-3.3.0.jar\"\n",
    "```\n",
    "\n",
    "Then make sure a text file with content is present in the `input_dir` directory on HDFS. If none is available, use the following:\n",
    "```shell\n",
    "curl -o sample.txt http://metaphorpsum.com/sentences/50\n",
    "hdfs dfs -put \"sample.txt\" \"input_dir\"\n",
    "```\n",
    "\n",
    "Finally, start the example, run the following from the directory containing the `.jar`, `mapper.py` and `reducer.py`:\n",
    "```shell\n",
    "hadoop jar hadoop-streaming-3.3.0.jar -mapper \"`pwd`/mapper.py\" -reducer \"`pwd`/reducer.py\" -input \"input_dir\" -output \"output_dir\"\n",
    "```\n",
    "\n",
    "To view the output:\n",
    "```shell\n",
    "hdfs dfs -cat \"output_dir/part-00000\"\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
